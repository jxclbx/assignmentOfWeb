{"meta":{"title":"jxclbx的小站","subtitle":"","description":"诶嘿","author":"Jxclbx","url":"http://jxclbx.github.io","root":"/"},"pages":[{"title":"","date":"2023-05-08T05:44:55.926Z","updated":"2023-04-28T05:47:48.000Z","comments":true,"path":"404.html","permalink":"http://jxclbx.github.io/404.html","excerpt":"","text":"404 很抱歉，您访问的页面不存在 可能是输入地址有误或该地址已被删除"},{"title":"所有分类","date":"2023-05-08T05:44:55.943Z","updated":"2023-04-28T05:53:46.000Z","comments":true,"path":"categories/index.html","permalink":"http://jxclbx.github.io/categories/index.html","excerpt":"","text":""},{"title":"","date":"2023-05-08T05:44:55.935Z","updated":"2023-04-28T05:53:42.000Z","comments":true,"path":"about/index.html","permalink":"http://jxclbx.github.io/about/index.html","excerpt":"","text":"下面写关于自己的内容"},{"title":"我的朋友们","date":"2023-05-08T05:44:56.031Z","updated":"2023-04-28T05:53:58.000Z","comments":true,"path":"friends/index.html","permalink":"http://jxclbx.github.io/friends/index.html","excerpt":"友情链接没有友链是万万不行滴！ 虽然博客是我自己写的，但是感谢他们对我一路的资瓷~","text":"友情链接没有友链是万万不行滴！ 虽然博客是我自己写的，但是感谢他们对我一路的资瓷~"}],"posts":[{"title":"Pytorch的奇妙体验","slug":"pytorch的奇妙体验","date":"2023-05-09T13:11:25.000Z","updated":"2023-05-09T16:13:29.360Z","comments":true,"path":"2023/05/09/pytorch的奇妙体验/","link":"","permalink":"http://jxclbx.github.io/2023/05/09/pytorch%E7%9A%84%E5%A5%87%E5%A6%99%E4%BD%93%E9%AA%8C/","excerpt":"","text":"DatasetPyTorch中的Dataset类是一个抽象基类，用于表示数据集。它定义了两个必须实现的方法：__len__() 和 __getitem__()。这个基类是通用的，但它本身无法处理特定类型的数据。因此，当您需要处理特定类型的数据（例如图像、文本等）时，您需要创建一个继承自Dataset类的自定义类，并实现这两个方法，以便根据您的数据加载和处理需求来处理数据。 在您提供的代码示例中，您创建了一个名为ImageDataset的自定义数据集类，它继承自PyTorch的Dataset类。这个类实现了 __len__() 和 __getitem__() 方法，用于处理存储为NumPy格式的图像数据。通过这种方式，您可以使用自定义的数据集类来适应您的特定数据类型和数据处理需求。 总结一下，原因在于PyTorch的Dataset类是一个通用的抽象基类，无法直接处理特定类型的数据。因此，需要创建自定义数据集类来实现针对特定数据类型的加载和处理。 网络112345678910111213141516class Net(nn.Module): def __init__(self): super(Net, self).__init__() self.conv1 = nn.Conv2d(3, 32, 5, stride=1) self.pool = nn.MaxPool2d(2, 2) self.conv2 = nn.Conv2d(32, 64, 5, stride=1) self.fc1 = nn.Linear(64 * 29 * 29, 128) self.fc2 = nn.Linear(128, 7) def forward(self, x): x = self.pool(F.relu(self.conv1(x))) x = self.pool(F.relu(self.conv2(x))) x = x.view(-1, 64 * 29 * 29) x = F.relu(self.fc1(x)) x = self.fc2(x) return x 效果如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647Epoch 1 loss: 1.622, train acc: 0.522, test acc: 0.522Epoch 2 loss: 1.012, train acc: 0.740, test acc: 0.736Epoch 3 loss: 0.707, train acc: 0.811, test acc: 0.814Epoch 4 loss: 0.581, train acc: 0.852, test acc: 0.854Epoch 5 loss: 0.501, train acc: 0.840, test acc: 0.845Epoch 6 loss: 0.416, train acc: 0.886, test acc: 0.884Epoch 7 loss: 0.385, train acc: 0.863, test acc: 0.852Epoch 8 loss: 0.334, train acc: 0.902, test acc: 0.884Epoch 9 loss: 0.315, train acc: 0.922, test acc: 0.902Epoch 10 loss: 0.255, train acc: 0.907, test acc: 0.868Epoch 11 loss: 0.247, train acc: 0.937, test acc: 0.916Epoch 12 loss: 0.193, train acc: 0.956, test acc: 0.924Epoch 13 loss: 0.158, train acc: 0.959, test acc: 0.921Epoch 14 loss: 0.149, train acc: 0.967, test acc: 0.931Epoch 15 loss: 0.132, train acc: 0.961, test acc: 0.914Epoch 16 loss: 0.117, train acc: 0.976, test acc: 0.935Epoch 17 loss: 0.091, train acc: 0.968, test acc: 0.927Epoch 18 loss: 0.084, train acc: 0.980, test acc: 0.933Epoch 19 loss: 0.073, train acc: 0.975, test acc: 0.925Epoch 20 loss: 0.060, train acc: 0.990, test acc: 0.938Epoch 21 loss: 0.060, train acc: 0.978, test acc: 0.922Epoch 22 loss: 0.063, train acc: 0.989, test acc: 0.938Epoch 23 loss: 0.048, train acc: 0.991, test acc: 0.938Epoch 24 loss: 0.042, train acc: 0.990, test acc: 0.935Epoch 25 loss: 0.035, train acc: 0.994, test acc: 0.941Epoch 26 loss: 0.036, train acc: 0.991, test acc: 0.941Epoch 27 loss: 0.029, train acc: 0.993, test acc: 0.938Epoch 28 loss: 0.033, train acc: 0.998, test acc: 0.943Epoch 29 loss: 0.038, train acc: 0.993, test acc: 0.942Epoch 30 loss: 0.026, train acc: 0.998, test acc: 0.945Epoch 31 loss: 0.017, train acc: 0.997, test acc: 0.944Epoch 34 loss: 0.021, train acc: 0.996, test acc: 0.939Epoch 35 loss: 0.017, train acc: 0.990, test acc: 0.936Epoch 36 loss: 0.020, train acc: 0.997, test acc: 0.950Epoch 37 loss: 0.014, train acc: 0.997, test acc: 0.951Epoch 38 loss: 0.011, train acc: 0.998, test acc: 0.945Epoch 39 loss: 0.007, train acc: 1.000, test acc: 0.938Epoch 40 loss: 0.011, train acc: 1.000, test acc: 0.944Epoch 41 loss: 0.007, train acc: 0.995, test acc: 0.940Epoch 42 loss: 0.012, train acc: 1.000, test acc: 0.940Epoch 43 loss: 0.008, train acc: 0.999, test acc: 0.945Epoch 44 loss: 0.009, train acc: 1.000, test acc: 0.946Epoch 45 loss: 0.007, train acc: 0.997, test acc: 0.943Epoch 46 loss: 0.007, train acc: 0.999, test acc: 0.948Epoch 49 loss: 0.009, train acc: 1.000, test acc: 0.948Epoch 50 loss: 0.004, train acc: 1.000, test acc: 0.948Finished Training 这种比较简单的网络结构可能存在一些缺陷： 模型表达能力有限：该网络的深度相对较浅，层数较少，可能无法充分提取输入数据的特征，从而导致模型表达能力不足。 容易出现过拟合：该网络没有使用正则化技术，如dropout等，容易在训练过程中出现过拟合问题，导致模型在测试集上表现不佳。 卷积核尺寸较大：该网络使用的卷积核尺寸为5，可能会导致卷积后的特征图失去一些细节信息，从而降低模型性能。 没有使用预训练模型：该网络是从头开始训练的，没有使用任何预训练模型，可能会导致训练时间较长，模型性能不佳。 以上是该网络可能存在的一些缺陷，可以通过调整网络结构、添加正则化技术、使用更小的卷积核等方式来提高模型性能。 简单提升CNN网络性能增加了更多卷积层，批量标准化层和 Dropout 层来提高性能： 123456789101112131415161718192021222324252627282930313233343536373839class Net(nn.Module): def __init__(self): super(Net, self).__init__() self.conv1 = nn.Conv2d(3, 32, 3, padding=1) self.bn1 = nn.BatchNorm2d(32) self.conv2 = nn.Conv2d(32, 64, 3, padding=1) self.bn2 = nn.BatchNorm2d(64) self.pool = nn.MaxPool2d(2, 2) self.conv3 = nn.Conv2d(64, 128, 3, padding=1) self.bn3 = nn.BatchNorm2d(128) self.conv4 = nn.Conv2d(128, 128, 3, padding=1) self.bn4 = nn.BatchNorm2d(128) self.conv5 = nn.Conv2d(128, 256, 3, padding=1) self.bn5 = nn.BatchNorm2d(256) self.conv6 = nn.Conv2d(256, 256, 3, padding=1) self.bn6 = nn.BatchNorm2d(256) self.fc1 = nn.Linear(256 * 8 * 8, 512) self.fc2 = nn.Linear(512, 256) self.fc3 = nn.Linear(256, 7) self.dropout = nn.Dropout(p=0.5) def forward(self, x): x = self.pool(F.relu(self.bn1(self.conv1(x)))) x = self.pool(F.relu(self.bn2(self.conv2(x)))) x = F.relu(self.bn3(self.conv3(x))) x = self.pool(F.relu(self.bn4(self.conv4(x)))) x = F.relu(self.bn5(self.conv5(x))) x = self.pool(F.relu(self.bn6(self.conv6(x)))) x = x.view(-1, 256 * 8 * 8) x = self.dropout(F.relu(self.fc1(x))) x = self.dropout(F.relu(self.fc2(x))) x = self.fc3(x) return x 效果如下： 1234567891011121314151617181920212223242526272829303132333435363738394041Epoch 1 loss: 1.625, train acc: 0.466, test acc: 0.465Epoch 2 loss: 1.146, train acc: 0.707, test acc: 0.712Epoch 3 loss: 0.603, train acc: 0.895, test acc: 0.883Epoch 4 loss: 0.313, train acc: 0.938, test acc: 0.937Epoch 5 loss: 0.175, train acc: 0.963, test acc: 0.951Epoch 6 loss: 0.135, train acc: 0.970, test acc: 0.956Epoch 7 loss: 0.092, train acc: 0.982, test acc: 0.967Epoch 8 loss: 0.071, train acc: 0.986, test acc: 0.968Epoch 9 loss: 0.055, train acc: 0.988, test acc: 0.971Epoch 10 loss: 0.043, train acc: 0.990, test acc: 0.971Epoch 11 loss: 0.036, train acc: 0.995, test acc: 0.968Epoch 12 loss: 0.028, train acc: 0.994, test acc: 0.979Epoch 13 loss: 0.024, train acc: 0.996, test acc: 0.977Epoch 14 loss: 0.016, train acc: 0.998, test acc: 0.977Epoch 15 loss: 0.017, train acc: 0.997, test acc: 0.978Epoch 16 loss: 0.017, train acc: 0.997, test acc: 0.978Epoch 17 loss: 0.015, train acc: 0.998, test acc: 0.981Epoch 18 loss: 0.013, train acc: 0.998, test acc: 0.979Epoch 19 loss: 0.010, train acc: 0.998, test acc: 0.976Epoch 20 loss: 0.008, train acc: 0.999, test acc: 0.978Epoch 21 loss: 0.008, train acc: 0.999, test acc: 0.980Epoch 22 loss: 0.007, train acc: 0.998, test acc: 0.980Epoch 23 loss: 0.006, train acc: 1.000, test acc: 0.979Epoch 24 loss: 0.005, train acc: 0.999, test acc: 0.978Epoch 25 loss: 0.006, train acc: 0.999, test acc: 0.977Epoch 26 loss: 0.005, train acc: 1.000, test acc: 0.979Epoch 27 loss: 0.005, train acc: 1.000, test acc: 0.977Epoch 28 loss: 0.004, train acc: 0.999, test acc: 0.978Epoch 29 loss: 0.005, train acc: 0.999, test acc: 0.976Epoch 30 loss: 0.004, train acc: 0.999, test acc: 0.982Epoch 31 loss: 0.004, train acc: 1.000, test acc: 0.977Epoch 32 loss: 0.006, train acc: 0.999, test acc: 0.979Epoch 33 loss: 0.005, train acc: 1.000, test acc: 0.978Epoch 34 loss: 0.004, train acc: 0.999, test acc: 0.976Epoch 35 loss: 0.003, train acc: 1.000, test acc: 0.982Epoch 36 loss: 0.003, train acc: 1.000, test acc: 0.977Epoch 37 loss: 0.003, train acc: 1.000, test acc: 0.979Epoch 38 loss: 0.003, train acc: 1.000, test acc: 0.976Epoch 39 loss: 0.003, train acc: 1.000, test acc: 0.979Epoch 40 loss: 0.002, train acc: 1.000, test acc: 0.982Epoch 41 loss: 0.002, train acc: 1.000, test acc: 0.980 网络2（Resnet）拟合速度更快，准确率更高的网络是残差网络（ResNet）。 ResNet是由微软提出的深度残差网络，其主要思想是通过引入残差连接来解决网络退化问题，从而允许网络更深更广，并提高了模型准确率和泛化能力。ResNet常用的版本包括ResNet-18、ResNet-34、ResNet-50、ResNet-101和ResNet-152等。 相比于其他深度神经网络，ResNet的优点有： 更快的训练速度：ResNet通过残差连接解决了梯度消失问题，使得网络可以更深更宽，从而能够更好地拟合数据，提高了训练速度。 更好的泛化能力：残差连接允许网络跨层直接传递信息，避免了信息的损失，使得网络可以更好地学习到数据的特征，提高了模型的泛化能力。 更高的准确率：ResNet通过引入残差连接，使得网络可以更深更宽，提高了模型的表达能力，从而能够更好地拟合数据，提高了模型的准确率。 但是，相比于其他深度神经网络，ResNet占用更多的显存，需要更多的计算资源来训练。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566class BasicBlock(nn.Module): def __init__(self, in_channels, out_channels, stride=1, downsample=None): super(BasicBlock, self).__init__() self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False) self.bn1 = nn.BatchNorm2d(out_channels) self.relu = nn.ReLU(inplace=True) self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False) self.bn2 = nn.BatchNorm2d(out_channels) self.downsample = downsample def forward(self, x): residual = x out = self.conv1(x) out = self.bn1(out) out = self.relu(out) out = self.conv2(out) out = self.bn2(out) if self.downsample: residual = self.downsample(x) out += residual out = self.relu(out) return outclass ResNet(nn.Module): def __init__(self, block, layers, num_classes=7): super(ResNet, self).__init__() self.in_channels = 64 self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False) self.bn1 = nn.BatchNorm2d(64) self.relu = nn.ReLU(inplace=True) self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1) self.layer1 = self.make_layer(block, 64, layers[0]) self.layer2 = self.make_layer(block, 128, layers[1], 2) self.layer3 = self.make_layer(block, 256, layers[2], 2) self.layer4 = self.make_layer(block, 512, layers[3], 2) self.avgpool = nn.AdaptiveAvgPool2d((1, 1)) self.fc = nn.Linear(512, num_classes) def make_layer(self, block, out_channels, blocks, stride=1): downsample = None if stride != 1 or self.in_channels != out_channels: downsample = nn.Sequential( nn.Conv2d(self.in_channels, out_channels, kernel_size=1, stride=stride, bias=False), nn.BatchNorm2d(out_channels) ) layers = [] layers.append(block(self.in_channels, out_channels, stride, downsample)) self.in_channels = out_channels for _ in range(1, blocks): layers.append(block(out_channels, out_channels)) return nn.Sequential(*layers) def forward(self, x): x = self.conv1(x) x = self.bn1(x) x = self.relu(x) x = self.maxpool(x) x = self.layer1(x) x = self.layer2(x) x = self.layer3(x) x = self.layer4(x) x = self.avgpool(x) x = x.view(x.size(0), -1) x = self.fc(x) return x Resnet存在着如下几个问题 网络的深度限制：尽管ResNet的提出解决了深度神经网络的梯度消失问题，但是当网络的深度增加时，ResNet仍然会出现梯度消失和梯度爆炸的问题。这限制了ResNet的深度。 特征重复利用不充分：在ResNet中，残差块中的特征并没有充分地被重复利用。相对于DenseNet，ResNet的特征传递方式是逐级传递，即特征只在当前和下一个块之间传递，而不是在所有块之间传递。 训练时间较长：由于ResNet是一个非常深的网络，所以它的训练时间会比较长，特别是当训练数据集很大时。 1234567891011121314151617181920212223242526272829Epoch 1 loss: 1.333, train acc: 0.757, test acc: 0.734Epoch 2 loss: 0.492, train acc: 0.938, test acc: 0.904Epoch 3 loss: 0.171, train acc: 0.982, test acc: 0.951Epoch 4 loss: 0.061, train acc: 0.996, test acc: 0.956Epoch 5 loss: 0.026, train acc: 0.999, test acc: 0.960Epoch 6 loss: 0.012, train acc: 1.000, test acc: 0.960Epoch 7 loss: 0.006, train acc: 1.000, test acc: 0.962Epoch 8 loss: 0.005, train acc: 1.000, test acc: 0.964Epoch 9 loss: 0.004, train acc: 1.000, test acc: 0.963Epoch 10 loss: 0.003, train acc: 1.000, test acc: 0.964Epoch 11 loss: 0.003, train acc: 1.000, test acc: 0.964Epoch 12 loss: 0.002, train acc: 1.000, test acc: 0.964Epoch 13 loss: 0.002, train acc: 1.000, test acc: 0.964Epoch 14 loss: 0.002, train acc: 1.000, test acc: 0.963Epoch 15 loss: 0.002, train acc: 1.000, test acc: 0.964Epoch 16 loss: 0.002, train acc: 1.000, test acc: 0.963Epoch 17 loss: 0.001, train acc: 1.000, test acc: 0.963Epoch 18 loss: 0.001, train acc: 1.000, test acc: 0.962Epoch 19 loss: 0.001, train acc: 1.000, test acc: 0.963Epoch 20 loss: 0.001, train acc: 1.000, test acc: 0.963Epoch 21 loss: 0.001, train acc: 1.000, test acc: 0.963Epoch 22 loss: 0.001, train acc: 1.000, test acc: 0.963Epoch 23 loss: 0.001, train acc: 1.000, test acc: 0.964Epoch 24 loss: 0.001, train acc: 1.000, test acc: 0.963Epoch 25 loss: 0.001, train acc: 1.000, test acc: 0.963Epoch 26 loss: 0.001, train acc: 1.000, test acc: 0.964Epoch 27 loss: 0.001, train acc: 1.000, test acc: 0.963Epoch 28 loss: 0.001, train acc: 1.000, test acc: 0.963Epoch 29 loss: 0.001, train acc: 1.000, test acc: 0.963 网络3（DenseNet）在DenseNet中，每个层的输出都会被连接到后续所有层的输入中，这使得每个层都可以直接获取到之前所有层的特征图，从而增加了特征重用的程度，避免了特征的浪费。在DenseNet中，特征图之间的连接可以使用张量拼接（concatenate）来实现。 具体地，DenseNet可以由多个密集块（Dense Block）和一个全局池化层（Global Pooling Layer）组成。每个密集块由多个卷积层和一个批量归一化层（Batch Normalization Layer）组成，卷积层的输出将被拼接到后续所有卷积层的输入中。全局池化层的输出将被送入一个全连接层和一个Softmax层中进行分类。 DenseNet的优点包括： 特征重用程度高：在DenseNet中，每个层都可以直接获取到之前所有层的特征图，从而增加了特征重用的程度，避免了特征的浪费。 模型参数较少：在DenseNet中，由于特征图之间的连接可以使用张量拼接来实现，所以模型参数较少。 准确率高：DenseNet在图像分类等任务上表现出色，达到了当时最好的性能。 然而，DenseNet也有一些缺点，如模型计算量较大、模型结构复杂等。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182class DenseLayer(nn.Module): def __init__(self, in_channels, growth_rate): super(DenseLayer, self).__init__() self.bn1 = nn.BatchNorm2d(in_channels) self.conv1 = nn.Conv2d(in_channels, growth_rate * 4, kernel_size=1, stride=1, bias=False) self.bn2 = nn.BatchNorm2d(growth_rate * 4) self.conv2 = nn.Conv2d(growth_rate * 4, growth_rate, kernel_size=3, stride=1, padding=1, bias=False) def forward(self, x): out = self.bn1(x) out = F.relu(out) out = self.conv1(out) out = self.bn2(out) out = F.relu(out) out = self.conv2(out) out = torch.cat((x, out), 1) return outclass DenseBlock(nn.Module): def __init__(self, in_channels, growth_rate, num_layers): super(DenseBlock, self).__init__() self.layers = nn.ModuleList([DenseLayer(in_channels + i * growth_rate, growth_rate) for i in range(num_layers)]) def forward(self, x): for layer in self.layers: x = layer(x) return xclass TransitionLayer(nn.Module): def __init__(self, in_channels, out_channels): super(TransitionLayer, self).__init__() self.bn = nn.BatchNorm2d(in_channels) self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False) def forward(self, x): out = self.bn(x) out = F.relu(out) out = self.conv(out) out = F.avg_pool2d(out, 2) return outclass DenseNet(nn.Module): def __init__(self, growth_rate, block_config, num_classes=7): super(DenseNet, self).__init__() self.conv1 = nn.Conv2d(3, growth_rate * 2, kernel_size=7, stride=2, padding=3, bias=False) self.bn1 = nn.BatchNorm2d(growth_rate * 2) self.relu = nn.ReLU(inplace=True) self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1) in_channels = growth_rate * 2 self.dense_blocks = nn.ModuleList() self.transition_layers = nn.ModuleList() for i, num_layers in enumerate(block_config): dense_block = DenseBlock(in_channels, growth_rate, num_layers) self.dense_blocks.append(dense_block) in_channels += num_layers * growth_rate if i != len(block_config) - 1: transition_layer = TransitionLayer(in_channels, in_channels // 2) self.transition_layers.append(transition_layer) in_channels = in_channels // 2 self.bn2 = nn.BatchNorm2d(in_channels) self.fc = nn.Linear(in_channels, num_classes) def forward(self, x): x = self.conv1(x) x = self.bn1(x) x = self.relu(x) x = self.maxpool(x) for i, dense_block in enumerate(self.dense_blocks): x = dense_block(x) if i != len(self.dense_blocks) - 1: x = self.transition_layers[i](x) x = self.bn2(x) x = F.relu(x) x = F.adaptive_avg_pool2 效果如下； 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748Epoch 1 loss: 1.401, train acc: 0.684, test acc: 0.669Epoch 2 loss: 0.556, train acc: 0.945, test acc: 0.921Epoch 3 loss: 0.188, train acc: 0.984, test acc: 0.951Epoch 4 loss: 0.074, train acc: 0.997, test acc: 0.956Epoch 5 loss: 0.024, train acc: 1.000, test acc: 0.965Epoch 6 loss: 0.012, train acc: 1.000, test acc: 0.966Epoch 7 loss: 0.007, train acc: 1.000, test acc: 0.964Epoch 8 loss: 0.005, train acc: 1.000, test acc: 0.965Epoch 9 loss: 0.004, train acc: 1.000, test acc: 0.967Epoch 10 loss: 0.003, train acc: 1.000, test acc: 0.966Epoch 11 loss: 0.003, train acc: 1.000, test acc: 0.965Epoch 12 loss: 0.003, train acc: 1.000, test acc: 0.966Epoch 13 loss: 0.002, train acc: 1.000, test acc: 0.967Epoch 14 loss: 0.002, train acc: 1.000, test acc: 0.967Epoch 15 loss: 0.002, train acc: 1.000, test acc: 0.966Epoch 16 loss: 0.002, train acc: 1.000, test acc: 0.967Epoch 17 loss: 0.002, train acc: 1.000, test acc: 0.966Epoch 18 loss: 0.001, train acc: 1.000, test acc: 0.966Epoch 19 loss: 0.001, train acc: 1.000, test acc: 0.966Epoch 20 loss: 0.001, train acc: 1.000, test acc: 0.966Epoch 21 loss: 0.001, train acc: 1.000, test acc: 0.966Epoch 22 loss: 0.001, train acc: 1.000, test acc: 0.966Epoch 23 loss: 0.001, train acc: 1.000, test acc: 0.966Epoch 24 loss: 0.001, train acc: 1.000, test acc: 0.966Epoch 25 loss: 0.001, train acc: 1.000, test acc: 0.966Epoch 26 loss: 0.001, train acc: 1.000, test acc: 0.967Epoch 27 loss: 0.001, train acc: 1.000, test acc: 0.967Epoch 28 loss: 0.001, train acc: 1.000, test acc: 0.966Epoch 29 loss: 0.001, train acc: 1.000, test acc: 0.966Epoch 30 loss: 0.001, train acc: 1.000, test acc: 0.967Epoch 31 loss: 0.001, train acc: 1.000, test acc: 0.967Epoch 34 loss: 0.001, train acc: 1.000, test acc: 0.967Epoch 36 loss: 0.001, train acc: 1.000, test acc: 0.968Epoch 37 loss: 0.001, train acc: 1.000, test acc: 0.967Epoch 38 loss: 0.001, train acc: 1.000, test acc: 0.967Epoch 39 loss: 0.001, train acc: 1.000, test acc: 0.967Epoch 40 loss: 0.001, train acc: 1.000, test acc: 0.968Epoch 41 loss: 0.001, train acc: 1.000, test acc: 0.968Epoch 42 loss: 0.000, train acc: 1.000, test acc: 0.968Epoch 43 loss: 0.000, train acc: 1.000, test acc: 0.967Epoch 44 loss: 0.000, train acc: 1.000, test acc: 0.968Epoch 45 loss: 0.000, train acc: 1.000, test acc: 0.968Epoch 46 loss: 0.000, train acc: 1.000, test acc: 0.967Epoch 47 loss: 0.000, train acc: 1.000, test acc: 0.968Epoch 48 loss: 0.000, train acc: 1.000, test acc: 0.968Epoch 49 loss: 0.000, train acc: 1.000, test acc: 0.968Epoch 50 loss: 0.000, train acc: 1.000, test acc: 0.968Finished Training 提高准确度方法： 调整超参数：尝试不同的学习率、批量大小、优化器和权重衰减。可以使用网格搜索或随机搜索找到最佳超参数组合。同时，可以考虑使用学习率调度器逐渐降低学习率。 更深或更宽的模型：尝试使用更复杂的模型，如更深或更宽的 ResNet、DenseNet 或其他现代架构。通常，更复杂的模型具有更大的表示能力，可以提高性能。 数据增强：使用数据增强技术，如随机旋转、翻转、缩放、剪裁和亮度调整等，可以扩展训练数据集并提高模型泛化能力。 正则化：使用正则化技术，如 L1 或 L2 正则化、Dropout 或 Batch Normalization，可以减轻过拟合并提高模型泛化能力。 更多数据：如果可能，尝试收集更多的训练数据。更多的数据有助于模型学习更多的特征，从而提高准确性。 早停法：在验证集上监控模型性能，当性能不再提高时，提前停止训练。这有助于防止过拟合。 预训练模型：使用预训练的模型作为初始模型，然后在您的数据集上进行微调。这样可以利用在大型数据集上学到的特征，加速收敛并提高性能。 集成方法：训练多个模型并将它们的输出结合起来。这可以是简单的平均，或者可以使用更复杂的技术，如投票或模型堆叠。这有助于提高模型的稳定性和准确性。 数据增强与上文不同，我在加入高斯噪声的基础上加入了图像旋转变换来提高模型的泛化能力 损失函数要改善模型的训练效果，您可以尝试使用其他损失函数。这里我使用Label Smoothing Cross Entropy损失。可以提高模型的泛化能力，因为它在训练过程中为模型提供了额外的正则化。 12345678910111213141516class LabelSmoothingCrossEntropy(nn.Module): def __init__(self, eps=0.1, reduction=&#x27;mean&#x27;): super(LabelSmoothingCrossEntropy, self).__init__() self.eps = eps self.reduction = reduction def forward(self, output, target): c = output.size(1) log_preds = F.log_softmax(output, dim=1) loss = F.nll_loss(log_preds, target, reduction=self.reduction) smooth_loss = -log_preds.mean(dim=1) if self.reduction == &#x27;mean&#x27;: smooth_loss = smooth_loss.mean() elif self.reduction == &#x27;sum&#x27;: smooth_loss = smooth_loss.sum() return loss * (1 - self.eps) + smooth_loss * self.eps BATCH_SIZEBatch size的选择对模型的训练效果和收敛速度有很大影响。然而，并没有一个固定的答案来确定最佳的batch size。 训练稳定性和收敛速度 ：较大的batch size可以让梯度下降过程更稳定，因为每个batch的平均梯度对噪声更不敏感。然而，大的batch size可能会导致训练过程收敛速度变慢，因为每次迭代更新权重的次数减少了。相反，较小的batch size可以提高训练速度，因为每个epoch内权重更新的次数增加，但可能会导致训练过程不稳定，这是由于小batch size中噪声较多。 泛化能力 ：有研究表明，较小的batch size可能有助于提高模型的泛化能力。这可能是因为较小的batch size在训练过程中引入了随机性和正则化，从而防止模型过拟合。 训练时间 ：较大的batch size可以减少每个epoch所需的迭代次数，从而减少同步和数据传输的开销，提高计算资源的利用率。但是，如果batch size过大，可能会导致GPU内存不足，进而影响训练速度。","categories":[{"name":"CV","slug":"CV","permalink":"http://jxclbx.github.io/categories/CV/"}],"tags":[{"name":"专业课","slug":"专业课","permalink":"http://jxclbx.github.io/tags/%E4%B8%93%E4%B8%9A%E8%AF%BE/"},{"name":"CV","slug":"CV","permalink":"http://jxclbx.github.io/tags/CV/"},{"name":"Pytorch","slug":"Pytorch","permalink":"http://jxclbx.github.io/tags/Pytorch/"}]},{"title":"网页设计与制作作业2","slug":"网页设计与制作作业2","date":"2023-05-09T05:55:09.000Z","updated":"2023-05-09T16:37:30.258Z","comments":true,"path":"2023/05/09/网页设计与制作作业2/","link":"","permalink":"http://jxclbx.github.io/2023/05/09/%E7%BD%91%E9%A1%B5%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%88%B6%E4%BD%9C%E4%BD%9C%E4%B8%9A2/","excerpt":"","text":"阐述 CSS 盒模型原理CSS盒模型是CSS中最基础的概念之一，它描述了一个元素在网页中的呈现方式。盒模型将一个元素看做是一个矩形盒子，由四个部分组成：内容区域（content）、内边距区域（padding）、边框区域（border）和外边距区域（margin）。 内容区域，也就是元素内部实际显示内容的区域。比如div元素，它的内容区域就是它所包含的文字、图片、列表等内容。 内边距区域，它是在内容区域和边框之间的空白区域，它为元素的内容提供空间。可以设置背景颜色、背景图片等样式属性。可以通过设置padding属性来调整内边距的大小。 边框区域，它包围着内边距和内容区域，并为元素提供了可见的边界。可以通过设置border属性来调整边框的大小、样式和颜色。 外边距区域，它是元素边框与相邻元素边框之间的空白区域。可以通过设置margin属性来调整外边距的大小。 举例阐述 CSS 中几种常用的选择器 通配符选择器（Wildcard Selector）：使用 * 选择器可以匹配页面上的所有元素。 标签选择器（Tag Selector）：使用标签名称作为选择器，例如 div、p、h1，可以选择指定类型的元素。 ID 选择器（ID Selector）：使用 # 加上元素的唯一标识符，例如 #myId，可以选择具有指定 ID 的元素。ID 应在页面中是唯一的。 类选择器（Class Selector）：使用 . 加上类名，例如 .myClass，可以选择具有指定类名的元素。多个元素可以共享相同的类。 伪类选择器（Pseudo-Class Selector）：使用 : 加上伪类名，例如 :hover、:first-child，可以选择特定状态或位置的元素。伪类可以根据用户交互或元素的位置进行选择。 具体效果剪文件夹内代码 举例阐述 CSS 几种定位方式绝对定位（Absolute Positioning）：使用 position: absolute; 将元素的位置相对于其最近的已定位祖先元素进行定位，如果没有已定位的祖先元素，则相对于文档的窗口进行定位。通过使用 top、bottom、left 和 right 属性，可以精确控制元素在页面上的位置。 相对定位（Relative Positioning）：使用 position: relative; 将元素相对于其正常位置进行定位。相对定位不会改变其他元素的布局，仍会占据原来的空间。通过使用 top、bottom、left 和 right 属性，可以相对于元素的正常位置调整其位置。 固定定位（Fixed Positioning）：使用 position: fixed; 将元素的位置相对于视口（浏览器窗口）进行定位，无论页面滚动与否，元素都会保持在固定的位置。通过使用 top、bottom、left 和 right 属性，可以确定元素在视口中的具体位置。 浮动定位（Float Positioning）：使用 float 属性将元素从正常的文档流中浮动到指定的位置。浮动元素可以向左或向右浮动，并使其周围的元素环绕在其周围。浮动通常用于创建多列布局。 做一个 CSS 3动画使用了 CSS 的样式和关键帧动画来实现了一个动画效果，通过定义样式和应用动画属性创建了一个渐变放大和旋转的圆形元素，并在动画结束后以渐变放大的方式显示了一段文字。 linear-gradient()：渐变函数用于创建线性渐变背景。在 .circle 类的样式中，使用了 linear-gradient(45deg, #ff8a00, #e52e71, #4c4c4c) 来创建一个从斜角 45 度开始的线性渐变背景。 border-radius：用于设置元素的边框圆角。在 .circle 类的样式中，使用了 border-radius: 50% 来将元素设置为一个圆形。 transform：用于对元素进行变换，例如旋转、缩放、平移等。在 .circle 和 .text 类的样式中，使用了 transform: translate(-50%, -50%) scale(0) 来设置元素的初始位置和大小。 animation 和 @keyframes：这是 CSS3 中用于创建动画的特性。在 .circle 和 .text 类的样式中，使用了 animation 属性来指定动画名称、持续时间、缓动函数和循环次数等。而 @keyframes 则定义了关键帧动画的不同阶段和样式","categories":[{"name":"HTML","slug":"HTML","permalink":"http://jxclbx.github.io/categories/HTML/"}],"tags":[{"name":"专业课","slug":"专业课","permalink":"http://jxclbx.github.io/tags/%E4%B8%93%E4%B8%9A%E8%AF%BE/"},{"name":"HTML","slug":"HTML","permalink":"http://jxclbx.github.io/tags/HTML/"},{"name":"网页","slug":"网页","permalink":"http://jxclbx.github.io/tags/%E7%BD%91%E9%A1%B5/"}]},{"title":"快速使用VSCode编写HTML文件","slug":"快速使用VSCode编写HTML文件","date":"2023-05-09T05:33:11.000Z","updated":"2023-05-09T16:36:32.559Z","comments":true,"path":"2023/05/09/快速使用VSCode编写HTML文件/","link":"","permalink":"http://jxclbx.github.io/2023/05/09/%E5%BF%AB%E9%80%9F%E4%BD%BF%E7%94%A8VSCode%E7%BC%96%E5%86%99HTML%E6%96%87%E4%BB%B6/","excerpt":"","text":"安装安装相关插件——搜索html,安装如下插件 再次打开插件商店，搜索open in browser 回到你的html文件，ctrl+s保存文件，然后shift+alt+b，在弹出的窗口中输入open in ,选择open in Other Browsers,如图(或者右键文件空白处，如图二红箭头所指向的两个，一个是用默认浏览器，一个是用其他浏览器。","categories":[{"name":"技术","slug":"技术","permalink":"http://jxclbx.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"vscode","slug":"vscode","permalink":"http://jxclbx.github.io/tags/vscode/"},{"name":"HTML","slug":"HTML","permalink":"http://jxclbx.github.io/tags/HTML/"}]},{"title":"Hexo博客自定义页面跳过渲染","slug":"Hexo博客自定义页面跳过渲染","date":"2023-05-08T07:39:01.000Z","updated":"2023-05-08T07:47:01.039Z","comments":true,"path":"2023/05/08/Hexo博客自定义页面跳过渲染/","link":"","permalink":"http://jxclbx.github.io/2023/05/08/Hexo%E5%8D%9A%E5%AE%A2%E8%87%AA%E5%AE%9A%E4%B9%89%E9%A1%B5%E9%9D%A2%E8%B7%B3%E8%BF%87%E6%B8%B2%E6%9F%93/","excerpt":"","text":"Hexo自定义原理Hexo 系列的博客中的文章都是经Hexo的主题渲染的静态网页。所以Hexo博客大部分都呈现出一种高度的统一化与规范化。不过 Hexo 提供了跳过渲染功能，使得我们可以直接在博客中放入自定义网页。 比如在博客中放入图片、自定义404.html、自定义About页面、简历等 创建自定义网页网页可以是自己编写的，也可以是别人现成的源码（下载喜欢的页面）。 网页编写完成后，在Hexo\\source目录下创建一个文件夹（文件夹名称任意，比如我创建的是about这个文件夹，部署完成后，访问http://mrlsm.github.io/about即可看到效果，依此类推） 将 html 文件放置于此文件夹，并重命名为 index.html 。 跳过渲染跳过渲染有下述两种方法： 在自定义页面的开头添加如下： 123---layout: false--- 添加该指令后，执行 hexo g命令时便会跳过该 index.html文件，使得index.html不受当前 hexo 主题影响，完全是一个独立的网页，如果网页引用了 css 或 js，css 和 js 需使用外链或者将css js 文件放入index.html同目录下引用。 引用图片亦是如此 在_config.yml文件中设置skip_render使用编辑器打开 Hexo 目录下的_config.yml文件，找到skip_render skip_render一般有以下四种常用参数： 跳过source目录下的 test.html: skip_render: test.html 跳过source目录下 test 文件夹内所有文件：skip_render: test&#x2F;* 跳过source目录下 test 文件夹内所有文件包括子文件夹以及子文件夹内的文件：skip_render: test&#x2F;**跳过多个路径： 123skip_render:- curriculumVitae/**- DecrypeMusic/** 最后执行 1hexo g -d","categories":[{"name":"技术","slug":"技术","permalink":"http://jxclbx.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://jxclbx.github.io/tags/hexo/"},{"name":"音乐","slug":"音乐","permalink":"http://jxclbx.github.io/tags/%E9%9F%B3%E4%B9%90/"}]},{"title":"算法设计实验题目","slug":"算法设计实验题目","date":"2023-05-06T08:37:01.000Z","updated":"2023-05-09T16:37:12.169Z","comments":true,"path":"2023/05/06/算法设计实验题目/","link":"","permalink":"http://jxclbx.github.io/2023/05/06/%E7%AE%97%E6%B3%95%E8%AE%BE%E8%AE%A1%E5%AE%9E%E9%AA%8C%E9%A2%98%E7%9B%AE/","excerpt":"","text":"GS算法匹配小狗狗 忘了 BFS DFS树的层序遍历（3月29日） 4.5没上课","categories":[{"name":"算法设计课程","slug":"算法设计课程","permalink":"http://jxclbx.github.io/categories/%E7%AE%97%E6%B3%95%E8%AE%BE%E8%AE%A1%E8%AF%BE%E7%A8%8B/"}],"tags":[{"name":"专业课","slug":"专业课","permalink":"http://jxclbx.github.io/tags/%E4%B8%93%E4%B8%9A%E8%AF%BE/"},{"name":"算法","slug":"算法","permalink":"http://jxclbx.github.io/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"Anaconda配置PyTorch环境","slug":"Anaconda配置PyTorch环境","date":"2023-05-05T14:36:39.000Z","updated":"2023-05-09T16:37:57.813Z","comments":true,"path":"2023/05/05/Anaconda配置PyTorch环境/","link":"","permalink":"http://jxclbx.github.io/2023/05/05/Anaconda%E9%85%8D%E7%BD%AEPyTorch%E7%8E%AF%E5%A2%83/","excerpt":"","text":"在Anaconda下安装Pytorch安装pytorch，有两种办法，一是pip，二是conda。不管什么样的方法，首先，都要安装最新的anaconda。 安装AnacondaAnaconda指的是一个开源的Python发行版本，其包含了conda、Python等180多个科学包及其依赖项。里面所包含的Jupyter Notebook是数据挖掘领域中最热门的工具。(例如Kaggle网站) 没安装Anaconda的小伙伴可以参考以下安装链接： https://blog.csdn.net/qq_4521807/article/details/112442577 安装Pytorch打开Anaconda Prompt在命令行格式下，输入代码，完成调用清华镜像、建立pytorch环境、安装pytorch、测试pytorch过程 调用清华镜像1conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/ 1conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/ 1conda config --set show_channel_urls yes 1conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/ 这个配置好以后，以后再安装其他的软件如果要用到清华镜像源网站就不用了重新配置了。 注意！如果切换镜像后当出现下载不了的情况，就先切换默认源，然后再修改另一个可以使用的conda源（一定要先恢复默认，再换另一个！！！） 切回默认源：1conda config --remove-key channels 创建Pytorch环境说真的，别在命令行里费那劲了，给你个GUI为嘛不用呢 1conda create -n pytorch python=3.7 查看环境是否安装成功 1conda info --envs 下载Pytorch根据自己的安装版本，在Pytorch官网寻找安装命令代码：Pytorch官网：https://pytorch.org/ 查看CUDA版本nvidia-smi solve environment需要比较长的时间，换了清华源之后就基本不需要挂梯子了 等待安装完成出现done 此时在vscode中可以在python解释器选择里看到pytorch环境的解释器： 按下F1键选择解释器，结束。","categories":[{"name":"技术","slug":"技术","permalink":"http://jxclbx.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"anaconda","slug":"anaconda","permalink":"http://jxclbx.github.io/tags/anaconda/"},{"name":"python","slug":"python","permalink":"http://jxclbx.github.io/tags/python/"}]},{"title":"耳机评测系列（一）--并不是东洋650，而是东洋1840","slug":"并不是东洋650，而是东洋1840——","date":"2023-05-04T14:59:49.000Z","updated":"2023-05-04T15:22:56.000Z","comments":true,"path":"2023/05/04/并不是东洋650，而是东洋1840——/","link":"","permalink":"http://jxclbx.github.io/2023/05/04/%E5%B9%B6%E4%B8%8D%E6%98%AF%E4%B8%9C%E6%B4%8B650%EF%BC%8C%E8%80%8C%E6%98%AF%E4%B8%9C%E6%B4%8B1840%E2%80%94%E2%80%94/","excerpt":"","text":"敬请期待","categories":[{"name":"评测","slug":"评测","permalink":"http://jxclbx.github.io/categories/%E8%AF%84%E6%B5%8B/"}],"tags":[{"name":"铁三角， Audio Technica","slug":"铁三角，-Audio-Technica","permalink":"http://jxclbx.github.io/tags/%E9%93%81%E4%B8%89%E8%A7%92%EF%BC%8C-Audio-Technica/"},{"name":"耳机","slug":"耳机","permalink":"http://jxclbx.github.io/tags/%E8%80%B3%E6%9C%BA/"},{"name":"评测","slug":"评测","permalink":"http://jxclbx.github.io/tags/%E8%AF%84%E6%B5%8B/"}]},{"title":"Anaconda常用操作","slug":"Anaconda常用配置","date":"2023-05-04T09:30:21.000Z","updated":"2023-05-05T15:47:22.000Z","comments":true,"path":"2023/05/04/Anaconda常用配置/","link":"","permalink":"http://jxclbx.github.io/2023/05/04/Anaconda%E5%B8%B8%E7%94%A8%E9%85%8D%E7%BD%AE/","excerpt":"","text":"在使用 python anaconda时，经常会用到很多常用操作，记录下来，方便以后更好地使用： CondaConda既是一个包管理器又是一个环境管理器。你肯定知道包管理器，它可以帮你发现和查看包。但是如果当我们想要安装一个包，但是这个包只支持跟我们目前使用的python不同的版本时。你只需要几行命令，就可以搭建起一个可以运行另外python版本的环境。这就是conda环境管理器的强大功能。 Conda常用命令1conda update conda # 升级conda 12conda create -n pytorch1 python=3 Astroid Babel#创建基于python3 ，包含Astroid 和 Babel 包，称为pytorch1的新环境，在/envs/bunnies文件夹里 123# 查看当前可用环境conda env list conda info --envs 123# 切换工作环境conda activate baseconda deactivate 123456# 复制一个环境conda create -n flowers --clone snowflakes # 重新命名：先 clone 一份 new name 的环境；删除 old name 的环境；conda create -n tf --clone rcnn # 克隆conda remove -n rcnn --all # 删除conda info -e # 重新查看环境 123# 删除一个环境conda remove -n flowers --allconda info -e # 查看是否环境已经成功被移除 12345678# 管理Python环境# 检查python版本conda search --full --name python conda search python # 使用模糊匹配 # 安装一个新的版本 conda create -n snakes python=3# 查看已经安装的环境 conda info -e 123456789101112# 管理包# 查看当前环境中包含的包和其版本列表 conda list # 查找一个包conda search beautifulsoup4 # 安装一个包conda install --name bunnies beautifulsoup4 # 你必须告诉conda你要安装环境的名字（-n bunies）否则它将会被安装到当前环境中 # 使用 pip 安装一个包，并可使用 conda list 进行查看；pip install see conda list 123# 删除整个anaconda rm -rf ~/miniconda OR rm -rf ~/anaconda # 直接删除整个文件夹，并去除.bashrc 中的配置文件即可，对环境影响较少；","categories":[{"name":"技术","slug":"技术","permalink":"http://jxclbx.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"anaconda","slug":"anaconda","permalink":"http://jxclbx.github.io/tags/anaconda/"},{"name":"python","slug":"python","permalink":"http://jxclbx.github.io/tags/python/"}]},{"title":"站内搜索","slug":"站内搜索","date":"2023-05-03T05:46:39.000Z","updated":"2023-05-03T05:53:12.000Z","comments":true,"path":"2023/05/03/站内搜索/","link":"","permalink":"http://jxclbx.github.io/2023/05/03/%E7%AB%99%E5%86%85%E6%90%9C%E7%B4%A2/","excerpt":"","text":"站内搜索配置代码 1234567891011121314# To use hexo search, you need to install the following plugins:# npm i hexo-generator-json-contentsearch: enable: true service: hexo # hexo, algolia, meilisearch algolia: searchAsYouType: true # If false, triggers the search only on submit. hitsPerPage: 5 # Set the number of hits per page. placeholder: &#x27;Search...&#x27; # The placeholder text of the input. meilisearch: placeholder: &#x27;Search...&#x27; searchKey: &#x27;&#x27; indexName: &#x27;&#x27; hostUrl: &#x27;&#x27; 显然这段没啥用，因为我们不需要使用algolia搜索等等 你需要安装 hexo-generator-json-content，并根据它的文档去做相应配置。 修改 主题配置文件 。 123search: enable: true service: hexo","categories":[{"name":"技术","slug":"技术","permalink":"http://jxclbx.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://jxclbx.github.io/tags/hexo/"},{"name":"站内搜索","slug":"站内搜索","permalink":"http://jxclbx.github.io/tags/%E7%AB%99%E5%86%85%E6%90%9C%E7%B4%A2/"}]},{"title":"Github+jsDelivr搭建个人图床","slug":"Github-jsDelivr搭建个人图床","date":"2023-05-02T16:13:51.000Z","updated":"2023-05-03T04:01:06.000Z","comments":true,"path":"2023/05/03/Github-jsDelivr搭建个人图床/","link":"","permalink":"http://jxclbx.github.io/2023/05/03/Github-jsDelivr%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%9B%BE%E5%BA%8A/","excerpt":"","text":"Github+jsDelivr图床经常写博文的朋友对床图肯定不陌生。使用markdown撰写博客，将图片放在床图网站生成外链统一管理，这样一份博文就可以发布在不同的平台，也避免了不同网页对同一张图片引用的。不过免费的床图网站有时不稳定，付费价格又都不便宜。 最近了解到了Github+jsDelivr的方式搭建个人床图，稳定快速免费。 搭建方法也比较简单，本文默认已经： 有Github账号 通过SSH与本地Git绑定 掌握基本的Git操作 那么，搭建床图仅需三步。 在GIthub建立一个仓库在创建GitHub仓库并与本地Git绑定中已经完成 将本地图片push到仓库 先将建好的仓库clone到本地 将需要上传的图片添加到对应文件夹 git push 图片就是保存在github仓库，每个仓库有1个G的容量限制。1个G？不叫事，那能存很多图片。如果你图片存满，那再建个新仓库就是了。 Github的资源在国内加载速度比较慢，所以需要用到CDN技术来加速。 CDN的全称是Content Delivery Network，即内容分发网络。CDN是构建在网络之上的内容分发网络，依靠部署在各地的边缘服务器，通过中心平台的负载均衡、内容分发、调度等功能模块，使用户就近获取所需内容，降低网络拥塞，提高用户访问响应速度和命中率。CDN的关键技术主要有内容存储和分发技术。 jsDelivr(https://cdn.jsdelivr.net)就是一种免费且快速的CDN，通过jsDelivr引用资源GIthub图片资源，即可实现图片加速。所以接下来的第三步，改写一下链接就搞定了。主题内部也是用了这种方法。 通过jsDelivr引用资源使用方法： 1https://cdn.jsdelivr.net/gh/你的用户名/你的仓库名@发布的版本号/文件路径 此处 1https://cdn.jsdelivr.net/gh/jxclbx/blogImages/文件路径 例如访问https://cdn.jsdelivr.net/gh/jxclbx/blogImages/imageSource/bg.jpg 得到如下效果： 图床接入 markdown的图片URL可以填入网络地址，并且paste image插件所输出的格式就是标准的markdown格式，而不是hexo的引用图片格式，我们只需在写完一篇blog后，多加入一步上传图片到github的步骤即可。 在merge后，直接将md文件中的url做替换，加入 1https://cdn.jsdelivr.net/gh/jxclbx/blogImages/imagePost/ 即可完成。","categories":[{"name":"技术","slug":"技术","permalink":"http://jxclbx.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"图床","slug":"图床","permalink":"http://jxclbx.github.io/tags/%E5%9B%BE%E5%BA%8A/"},{"name":"jsDelivr","slug":"jsDelivr","permalink":"http://jxclbx.github.io/tags/jsDelivr/"},{"name":"git","slug":"git","permalink":"http://jxclbx.github.io/tags/git/"}]},{"title":"创建GitHub仓库并与本地Git绑定","slug":"创建GitHub仓库并与本地Git绑定","date":"2023-05-02T13:40:34.000Z","updated":"2023-05-03T03:54:06.000Z","comments":true,"path":"2023/05/02/创建GitHub仓库并与本地Git绑定/","link":"","permalink":"http://jxclbx.github.io/2023/05/02/%E5%88%9B%E5%BB%BAGitHub%E4%BB%93%E5%BA%93%E5%B9%B6%E4%B8%8E%E6%9C%AC%E5%9C%B0Git%E7%BB%91%E5%AE%9A/","excerpt":"","text":"为了创建一个图床 有Github账号 通过SSH与本地Git绑定 掌握基本的Git操作 这三步是缺一不可的，现在先来将SSH绑定git 创建一个新的仓库我们点击“New repository”创建一个新的仓库： 得到SSH地址 绑定SSH双击git-bash.exe，在本地创建ssh key： 1ssh-keygen -t rsa -C &quot;your_email@youremail.com&quot; 然后成功后会在User文件夹对应的用户下创建.ssh文件夹，其中有一个id_rsa.pub文件，我们复制其中的key: 之后返回github，进入 Account Settings（账户配置），左边选择SSH and GPG Keys选项 其中的title随便填，下面的粘贴在你电脑上生成的key。点击添加之后，则添加成功： 验证是否绑定本地成功，在git-bash中验证，输入指令： 1ssh -T git@github.com 如果第一次执行该指令，则会提示是否continue继续，如果我们输入yes就会看到成功信息： 1ssh -T git@github.com github不支持shell这个可以忽略。 1Hi jxclbx! You&#x27;ve successfully authenticated, but GitHub does not provide shell access. Git操作由于GitHub每次执行commit操作时，都会记录username和email，所以要设置它们： 12git config --global user.name &quot;jxclbx&quot;git config --global user.email &quot;13001392777@163.com&quot; Clone到本地1git clone git@github.com:jxclbx/blogImages.git 此时在目录下会到一个隐藏的.git文件夹，该文件夹是Git用来跟踪管理版本库的，然后将所有文件添加到仓库，并提交文件： 1git add . 1git commit -m &quot; &quot; Add &amp; Commitgit commit 是 Git 版本控制系统中用于保存本地仓库更改的命令。当你在本地 Git 仓库中更改文件时，可以使用 git commit 创建一个新的快照并将其添加到 Git 历史记录中。这有助于跟踪你随着时间推移所做的更改并与其他人共同开发同一项目。 要使用 git commit，你首先需要使用 git add 将要提交的更改加入到暂存区中。这告诉 Git 你想要包含在提交中的更改内容。一旦你将更改加入到暂存区中，就可以使用以下命令将其提交： -m 标志用于添加提交信息，描述你所做的更改。编写清晰和描述性的提交信息非常重要，这样其他开发人员可以轻松地理解你所做的更改。 如果你想在提交中包含工作目录中的所有更改，可以使用以下命令： 1git commit -a -m &quot;提交信息&quot; -a 标志告诉 Git 自动将仓库中所有已修改或已删除的更改加入到暂存区中。 提交完成后，可以将其推送到远程仓库以与他人共享更改或保留更改的备份。 暂存区暂存区是 Git 版本控制系统中的一个概念，它是介于工作目录和 Git 仓库之间的一个中间状态，也被称为 Git 的“索引”（index）。它是用于临时存储已修改或已删除文件的地方，以便在下一次提交时包含这些更改。 暂存区在本地 Git 仓库的 .git 目录中的 index 文件中。每次使用 git add 命令将文件添加到暂存区时，Git 会将这些更改写入 index 文件中。在执行 git commit 命令之前，你可以使用 git status 命令来查看哪些文件已经被添加到暂存区，哪些文件还未被添加。 需要注意的是，暂存区只是一个中间状态，只有执行 git commit 命令将暂存区中的更改提交到 Git 仓库后，这些更改才会被永久保存下来。如果你在暂存区中添加了一个文件，但之后又对该文件进行了修改，那么只有重新使用 git add 命令将该文件添加到暂存区，之后再使用 git commit 命令才能将最新的更改提交到 Git 仓库中。 关于远程仓库：remote在 Git 中，remote 表示远程仓库的别名或名称。当你从远程仓库中获取代码或将代码推送到远程仓库时，需要使用远程仓库的名称。为了方便起见，Git 允许为每个远程仓库分配一个别名，这个别名就是 remote。 在 git remote add 命令中，remote 参数指定了新远程仓库的名称或别名，origin 就是一个常用的远程仓库别名。在这个命令中，origin 将被用作指向远程仓库的别名，而 git@github.com:jxclbx/blogImages.git 则是该远程仓库的 URL。这个命令将把远程仓库 git@github.com:jxclbx/blogImages.git 添加到本地 Git 仓库中，并将其命名为 origin。 在添加远程仓库后，你可以使用 git remote -v 命令查看所有已添加的远程仓库，包括它们的别名和 URL。 这个错误意味着在尝试将本地 Git 仓库连接到远程仓库时，Git 发现已经存在一个名为 origin 的远程仓库。这通常发生在你尝试在已经存在 origin 的情况下再次运行 git remote add origin 命令，或者在克隆仓库时指定了一个与 origin 名称相同的远程仓库。 要解决这个错误，可以尝试以下方法： 1git remote rm origin 本地仓库建立完成此时我们的本地仓库就建立好了。 然后我们的本地仓库要关联GitHub的仓库，直接将本地仓库关联远程GitHub仓库地址即可 1git remote add origin git@github.com:jxclbx/blogImages.git 上传本地代码至GitHub下面要上传本地代码至GitHub，但是前提是远程仓库不能使空的，所以我们在远程仓库中创建一个README.md的文件： 本地仓库也创建一个一模一样的README.md文件即可，然后使用git pull origin master远程更新一下。 然后我们在原来的git bash中提交本地仓库中的web工程源代码： 1git push -u origin master error: src refspec master does not match any确认本地 Git 仓库中是否存在名为 master 的分支。使用以下命令查看本地分支： 1git branch 如果 master 分支不存在，则可以使用以下命令创建该分支： 1git checkout -b master Pull request 出现 There isn’t anything to compare.请移步另一篇文章。至此，已经绑定以及创建仓库。","categories":[{"name":"技术","slug":"技术","permalink":"http://jxclbx.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"git","slug":"git","permalink":"http://jxclbx.github.io/tags/git/"},{"name":"ssh","slug":"ssh","permalink":"http://jxclbx.github.io/tags/ssh/"}]},{"title":"你好，五月！","slug":"你好，五月！","date":"2023-04-28T06:11:48.000Z","updated":"2023-05-03T03:34:52.000Z","comments":true,"path":"2023/04/28/你好，五月！/","link":"","permalink":"http://jxclbx.github.io/2023/04/28/%E4%BD%A0%E5%A5%BD%EF%BC%8C%E4%BA%94%E6%9C%88%EF%BC%81/","excerpt":"","text":"五月一个寻常的五月，往往以一个寻常的错误开篇。 寻常的不能再寻常 寻常到……front-matter的Headimg千万不要忘了打后缀名，本地路径打上了后缀名也会因为外部链接没法引用这个路径下的image而无法显示。。最后投奔了图床…… 开始真正的五月在北京开启，爬展花花卡丁车 好在五月是这样的一个轻松充实的基调 （富士真好玩.jpg 让我们和四月说一声再见吧，希望五月的风带来我想见的你，愿你想要的明天，都会如约而至。","categories":[{"name":"浮生","slug":"浮生","permalink":"http://jxclbx.github.io/categories/%E6%B5%AE%E7%94%9F/"}],"tags":[{"name":"五月","slug":"五月","permalink":"http://jxclbx.github.io/tags/%E4%BA%94%E6%9C%88/"}]},{"title":"VS_Code配置Python解释器","slug":"VS-Code配置Python解释器","date":"2023-04-26T13:21:53.000Z","updated":"2023-05-09T05:36:24.202Z","comments":true,"path":"2023/04/26/VS-Code配置Python解释器/","link":"","permalink":"http://jxclbx.github.io/2023/04/26/VS-Code%E9%85%8D%E7%BD%AEPython%E8%A7%A3%E9%87%8A%E5%99%A8/","excerpt":"","text":"我们熟悉的老朋友VS Code今天cv2莫名其妙报错，经过一番排查，得到是Python自身出了问题，故记录一下VSC与anaconda配置其的过程 VSCode首先，我们需要在环境变量中添加 12C:\\Users\\13001\\AppData\\Local\\Programs\\Python\\Python37C:\\Users\\13001\\AppData\\Local\\Programs\\Python\\Python37\\Scripts 再在VSCode中，Ctrl+Shift+P 或者 View &gt; Command Palette，打开命令面板输入 Python: Select Interpreter 选择Python的安装路径 可以使用上方的刷新符号来更新已经卸载的python版本的状态使其消失 选择好解释器后，就可以愉快的开始使用了","categories":[{"name":"技术","slug":"技术","permalink":"http://jxclbx.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"python","slug":"python","permalink":"http://jxclbx.github.io/tags/python/"},{"name":"垃圾py","slug":"垃圾py","permalink":"http://jxclbx.github.io/tags/%E5%9E%83%E5%9C%BEpy/"},{"name":"vscode","slug":"vscode","permalink":"http://jxclbx.github.io/tags/vscode/"}]},{"title":"公开前：配置主题","slug":"公开前：配置主题","date":"2023-04-23T15:35:32.000Z","updated":"2023-05-03T03:35:48.000Z","comments":true,"path":"2023/04/23/公开前：配置主题/","link":"","permalink":"http://jxclbx.github.io/2023/04/23/%E5%85%AC%E5%BC%80%E5%89%8D%EF%BC%9A%E9%85%8D%E7%BD%AE%E4%B8%BB%E9%A2%98/","excerpt":"","text":"首先，非常激动，非常开心，我打开了撰写blog的大门。 配置主题首先是更改主题 1npm i hexo-theme-volantis 这步是为了将主题安置到 blog\\node_modules\\hexo-theme-volantis 关于背景图片的替换将图片放置在 node_modules\\hexo-theme-volantis\\source\\images 中，再将 12345678cover: height_scheme: full # full, half layout_scheme: dock # blank (留白), search (搜索), dock (坞), featured (精选), focus (焦点) display: home: true archive: true others: false # can be written in front-matter &#x27;cover: true&#x27; background: /images/bg.jpg # background image 的background字段更改为相对路径即可 关于引用图片hexo-renderer-marked 3.1.0 引入了一个新的选项，其允许你无需使用 asset_img 标签插件就可以在 markdown 中嵌入图片 然后再在 _config.yml中更改代码块 1234post_asset_folder: truemarked: prependRoot: true postAsset: true 后在 _posts 文件夹中新建与post名相同的文件夹即可","categories":[{"name":"技术","slug":"技术","permalink":"http://jxclbx.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"自言自语","slug":"自言自语","permalink":"http://jxclbx.github.io/tags/%E8%87%AA%E8%A8%80%E8%87%AA%E8%AF%AD/"}]},{"title":"Hello World","slug":"hello-world","date":"2023-04-22T15:54:53.000Z","updated":"2023-05-02T15:55:08.000Z","comments":true,"path":"2023/04/22/hello-world/","link":"","permalink":"http://jxclbx.github.io/2023/04/22/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}],"categories":[{"name":"CV","slug":"CV","permalink":"http://jxclbx.github.io/categories/CV/"},{"name":"HTML","slug":"HTML","permalink":"http://jxclbx.github.io/categories/HTML/"},{"name":"技术","slug":"技术","permalink":"http://jxclbx.github.io/categories/%E6%8A%80%E6%9C%AF/"},{"name":"算法设计课程","slug":"算法设计课程","permalink":"http://jxclbx.github.io/categories/%E7%AE%97%E6%B3%95%E8%AE%BE%E8%AE%A1%E8%AF%BE%E7%A8%8B/"},{"name":"评测","slug":"评测","permalink":"http://jxclbx.github.io/categories/%E8%AF%84%E6%B5%8B/"},{"name":"浮生","slug":"浮生","permalink":"http://jxclbx.github.io/categories/%E6%B5%AE%E7%94%9F/"}],"tags":[{"name":"专业课","slug":"专业课","permalink":"http://jxclbx.github.io/tags/%E4%B8%93%E4%B8%9A%E8%AF%BE/"},{"name":"CV","slug":"CV","permalink":"http://jxclbx.github.io/tags/CV/"},{"name":"Pytorch","slug":"Pytorch","permalink":"http://jxclbx.github.io/tags/Pytorch/"},{"name":"HTML","slug":"HTML","permalink":"http://jxclbx.github.io/tags/HTML/"},{"name":"网页","slug":"网页","permalink":"http://jxclbx.github.io/tags/%E7%BD%91%E9%A1%B5/"},{"name":"vscode","slug":"vscode","permalink":"http://jxclbx.github.io/tags/vscode/"},{"name":"hexo","slug":"hexo","permalink":"http://jxclbx.github.io/tags/hexo/"},{"name":"音乐","slug":"音乐","permalink":"http://jxclbx.github.io/tags/%E9%9F%B3%E4%B9%90/"},{"name":"算法","slug":"算法","permalink":"http://jxclbx.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"anaconda","slug":"anaconda","permalink":"http://jxclbx.github.io/tags/anaconda/"},{"name":"python","slug":"python","permalink":"http://jxclbx.github.io/tags/python/"},{"name":"铁三角， Audio Technica","slug":"铁三角，-Audio-Technica","permalink":"http://jxclbx.github.io/tags/%E9%93%81%E4%B8%89%E8%A7%92%EF%BC%8C-Audio-Technica/"},{"name":"耳机","slug":"耳机","permalink":"http://jxclbx.github.io/tags/%E8%80%B3%E6%9C%BA/"},{"name":"评测","slug":"评测","permalink":"http://jxclbx.github.io/tags/%E8%AF%84%E6%B5%8B/"},{"name":"站内搜索","slug":"站内搜索","permalink":"http://jxclbx.github.io/tags/%E7%AB%99%E5%86%85%E6%90%9C%E7%B4%A2/"},{"name":"图床","slug":"图床","permalink":"http://jxclbx.github.io/tags/%E5%9B%BE%E5%BA%8A/"},{"name":"jsDelivr","slug":"jsDelivr","permalink":"http://jxclbx.github.io/tags/jsDelivr/"},{"name":"git","slug":"git","permalink":"http://jxclbx.github.io/tags/git/"},{"name":"ssh","slug":"ssh","permalink":"http://jxclbx.github.io/tags/ssh/"},{"name":"五月","slug":"五月","permalink":"http://jxclbx.github.io/tags/%E4%BA%94%E6%9C%88/"},{"name":"垃圾py","slug":"垃圾py","permalink":"http://jxclbx.github.io/tags/%E5%9E%83%E5%9C%BEpy/"},{"name":"自言自语","slug":"自言自语","permalink":"http://jxclbx.github.io/tags/%E8%87%AA%E8%A8%80%E8%87%AA%E8%AF%AD/"}]}